\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{hyperref}
\geometry{margin=2.5cm}
\setlength{\parskip}{1em}
\setlength{\parindent}{0pt}
\pagestyle{fancy}
\fancyhf{}
\rhead{DM Probabilités}
\lhead{Loi de Rayleigh}
\rfoot{\thepage}

\title{Devoir Maison : Probabilités et Statistiques \\ Loi de Rayleigh}
\author{Nom : Calmand Dimitri | Scia 2026}
\date{}

\begin{document}
\maketitle

\section*{Partie 1}

\subsection*{1. Justification que $f(x,\sigma)$ est une densité de probabilité}

La fonction est définie comme suit :
\[
f(x, \sigma) = 
\begin{cases}
0 & \text{si } x < 0, \\
\dfrac{x}{\sigma^2} \exp\left(-\dfrac{x^2}{2\sigma^2}\right) & \text{si } x \ge 0.
\end{cases}
\]

\vspace{0.5em}
\textbf{Positivité :} Pour tout $x \ge 0$ et $\sigma > 0$, $f(x,\sigma) \ge 0$.\\

\textbf{Intégrabilité :} On vérifie que $\int_{-\infty}^{\infty} f(x)\,dx = 1$ :
\[
\int_0^\infty \dfrac{x}{\sigma^2} e^{-x^2/(2\sigma^2)} dx.
\]
Posons $u = \dfrac{x^2}{2\sigma^2}$, alors $du = \dfrac{x}{\sigma^2} dx$, ce qui donne :
\[
\int_0^\infty e^{-u} du = 1.
\]
Donc $f(x,\sigma)$ est bien une densité de probabilité sur $\mathbb{R}$.

\vspace{1em}
\section*{2. Montrer que $Y = X^2$ suit une loi exponentielle}

Soit $X$ une variable aléatoire suivant une loi de Rayleigh de paramètre $\sigma > 0$, dont la densité est :

\[
f_X(x) =
\begin{cases}
0 & \text{si } x < 0, \\
\dfrac{x}{\sigma^2} e^{-x^2 / (2\sigma^2)} & \text{si } x \geq 0.
\end{cases}
\]

Définissons la variable aléatoire $Y = X^2$. On souhaite déterminer la loi de $Y$.

\subsection*{Changement de variable}

Comme $X \geq 0$, la transformation $Y = X^2$ est bijective sur $\mathbb{R}_+$. La fonction réciproque est $x = \sqrt{y}$, et la dérivée est :

\[
\frac{dx}{dy} = \frac{1}{2\sqrt{y}}.
\]

On utilise la formule de changement de variable pour obtenir la densité $f_Y$ de $Y$ :
\[
f_Y(y) = f_X(\sqrt{y}) \cdot \left| \frac{dx}{dy} \right| = \frac{\sqrt{y}}{\sigma^2} e^{-y/(2\sigma^2)} \cdot \frac{1}{2\sqrt{y}} = \frac{1}{2\sigma^2} e^{-y/(2\sigma^2)}.
\]

Cette densité est définie pour $y \geq 0$, et on reconnaît la densité d'une loi exponentielle de paramètre $\lambda = \dfrac{1}{2\sigma^2}$ :
\[
f_Y(y) = \lambda e^{-\lambda y}, \quad y \geq 0.
\]

\subsection*{Conclusion}

La variable $Y = X^2$ suit une loi exponentielle de paramètre $\lambda = \dfrac{1}{2\sigma^2}$.

\[
\boxed{Y = X^2 \sim \text{Exp}\left( \dfrac{1}{2\sigma^2} \right)}
\]






\section*{3. Espérance de $X$}

On cherche à calculer $\mathbb{E}(X)$, où $X$ suit une loi de Rayleigh de paramètre $\sigma > 0$, avec densité :
\[
f(x) = \begin{cases}
0 & \text{si } x < 0, \\
\dfrac{x}{\sigma^2} e^{-x^2 / (2\sigma^2)} & \text{si } x \geq 0.
\end{cases}
\]

Par définition de l’espérance :
\[
\mathbb{E}(X) = \int_0^{+\infty} x \cdot f(x) \, dx = \int_0^{+\infty} x \cdot \frac{x}{\sigma^2} e^{-x^2 / (2\sigma^2)} dx = \frac{1}{\sigma^2} \int_0^{+\infty} x^2 e^{-x^2 / (2\sigma^2)} dx.
\]

On pose le changement de variable :
\[
u = \frac{x}{\sigma\sqrt{2}} \quad \Rightarrow \quad x = u \sigma\sqrt{2}, \quad dx = \sigma\sqrt{2} \, du.
\]

L’intégrale devient alors :
\[
\mathbb{E}(X) = \frac{1}{\sigma^2} \int_0^{+\infty} (u \sigma \sqrt{2})^2 e^{-u^2} \cdot \sigma \sqrt{2} \, du = \frac{1}{\sigma^2} \cdot \sigma^3 2\sqrt{2} \int_0^{+\infty} u^2 e^{-u^2} du.
\]

On utilise la formule :
\[
\int_0^{+\infty} u^2 e^{-u^2} du = \frac{\sqrt{\pi}}{4},
\]
ce qui donne :
\[
\mathbb{E}(X) = \frac{1}{\sigma^2} \cdot \sigma^3 \cdot 2\sqrt{2} \cdot \frac{\sqrt{\pi}}{4} = \sigma \cdot \sqrt{\frac{\pi}{2}}.
\]

\boxed{\mathbb{E}(X) = \sigma \sqrt{\dfrac{\pi}{2}}}

\vspace{1em}
\section*{4. Calcul de $\mathbb{E}(X^2)$ à partir de la variance}

On admet que :
\[
\text{Var}(X) = \left(\frac{4 - \pi}{2}\right) \sigma^2.
\]

Or, par définition de la variance :
\[
\text{Var}(X) = \mathbb{E}(X^2) - \left[\mathbb{E}(X)\right]^2.
\]

En remplaçant :
\[
\left(\frac{4 - \pi}{2}\right)\sigma^2 = \mathbb{E}(X^2) - \left(\sigma \sqrt{\frac{\pi}{2}}\right)^2.
\]

\[
\left(\frac{4 - \pi}{2}\right)\sigma^2 = \mathbb{E}(X^2) - \frac{\pi}{2} \sigma^2.
\]

\[
\mathbb{E}(X^2) = \left( \frac{4 - \pi}{2} + \frac{\pi}{2} \right) \sigma^2 = 2\sigma^2.
\]

\boxed{\mathbb{E}(X^2) = 2\sigma^2}

\vspace{1em}

\vspace{1em}
\section*{5. Estimateurs par la méthode des moments}

La méthode des moments consiste à égaler les moments empiriques aux moments théoriques pour estimer le paramètre inconnu $\sigma$.

\subsection*{Premier moment}

On a, d'après la question 3 :
\[
\mathbb{E}(X) = \sigma \sqrt{\frac{\pi}{2}}.
\]
On remplace cette espérance par la moyenne empirique :
\[
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i.
\]
On obtient l’estimateur suivant :
\[
\hat{\sigma}_1 = \bar{X}_n \cdot \sqrt{\frac{2}{\pi}}.
\]

\subsection*{Deuxième moment}

D'après la question 4 :
\[
\mathbb{E}(X^2) = 2\sigma^2.
\]
En égalant avec le moment empirique :
\[
M_2 = \frac{1}{n} \sum_{i=1}^n X_i^2,
\]
on obtient :
\[
M_2 = 2\sigma^2 \quad \Rightarrow \quad \hat{\sigma}_2 = \sqrt{\frac{1}{2n} \sum_{i=1}^n X_i^2}.
\]

\vspace{1em}
\section*{6. Estimateur du maximum de vraisemblance}

On considère $X_1, \dots, X_n$ indépendants et de même loi $\mathcal{R}(\sigma)$ (Rayleigh). La fonction de vraisemblance s’écrit :
\[
\mathcal{L}(\sigma) = \prod_{i=1}^n f(X_i) = \prod_{i=1}^n \left( \frac{X_i}{\sigma^2} \exp\left( -\frac{X_i^2}{2\sigma^2} \right) \right).
\]

On travaille sur la log-vraisemblance :
\[
\ell(\sigma) = \log \mathcal{L}(\sigma) = \sum_{i=1}^n \left[ \log(X_i) - 2\log(\sigma) - \frac{X_i^2}{2\sigma^2} \right].
\]

On dérive par rapport à $\sigma$ :
\[
\ell'(\sigma) = \sum_{i=1}^n \left[ -\frac{2}{\sigma} + \frac{X_i^2}{\sigma^3} \right] = -\frac{2n}{\sigma} + \frac{1}{\sigma^3} \sum_{i=1}^n X_i^2.
\]

On annule cette dérivée :
\[
-\frac{2n}{\sigma} + \frac{1}{\sigma^3} \sum_{i=1}^n X_i^2 = 0.
\]

\[
\Rightarrow \quad \sum_{i=1}^n X_i^2 = 2n\sigma^2.
\]

\[
\Rightarrow \quad \hat{\sigma}_{\text{EMV}} = \sqrt{\frac{1}{2n} \sum_{i=1}^n X_i^2}.
\]

On retrouve ici le même estimateur que celui issu du deuxième moment.

\boxed{\hat{\sigma}_{\text{EMV}} = \sqrt{\frac{1}{2n} \sum_{i=1}^n X_i^2}}

\newpage
\section*{Partie 2 — Estimation de $\sigma$ et intervalles de confiance}

\vspace{1em}
\subsection*{1(a). Expression de l'estimateur du maximum de vraisemblance en fonction de $T_n$}

On considère la variable aléatoire :
\[
T_n = \sum_{k=1}^n X_k^2,
\]
où les $X_k$ sont indépendants et suivent une loi de Rayleigh de paramètre $\sigma$.

D'après la question 6 de la Partie 1, l'estimateur du maximum de vraisemblance est donné par :
\[
\hat{\sigma}_{\text{EMV}} = \sqrt{\frac{1}{2n} \sum_{k=1}^n X_k^2} = \sqrt{\frac{T_n}{2n}}.
\]

\boxed{\hat{\sigma}_{\text{EMV}} = \sqrt{\dfrac{T_n}{2n}}}

\vspace{1em}
\subsection*{1(b). Limite de $T_n$ pour la construction d’un intervalle de confiance}

Bien que $T_n$ soit une somme d’observations aléatoires, sa loi dépend du paramètre inconnu $\sigma$.

Plus précisément, on admet que :
\[
T_n \sim \text{Gamma}(n, 2\sigma^2),
\]
ce qui signifie que la densité de $T_n$ dépend directement de $\sigma^2$.

Ainsi, tant que $\sigma^2$ n'est pas connu, on ne peut pas directement déterminer les quantiles de la loi de $T_n$, ce qui rend impossible la construction d'un intervalle de confiance basé directement sur $T_n$.

Pour contourner cela, on cherche une variable pivot, c’est-à-dire une variable dont la loi ne dépend pas de $\sigma$. Cela nous conduit à considérer la variable $T_n / \sigma^2$.

\vspace{1em}
\subsection*{2. Loi de $\dfrac{X_k^2}{\sigma^2}$}

Soit $X_k \sim \mathcal{R}(\sigma)$.

D’après la Partie 1, on a $X_k^2 \sim \text{Exp}(\lambda = \frac{1}{2\sigma^2})$.

En posant :
\[
Y_k = \frac{X_k^2}{\sigma^2},
\]
on effectue un changement d’échelle sur une variable exponentielle. Le résultat est une variable exponentielle de paramètre $1/2$ :
\[
Y_k \sim \text{Exp}\left(\frac{1}{2}\right).
\]

Mais une loi exponentielle de paramètre $1/2$ est équivalente à une loi $\chi^2$ à deux degrés de liberté. En effet, la densité est :
\[
f(y) = \frac{1}{2} e^{-y/2} \quad \text{pour } y \geq 0,
\]
ce qui correspond à la densité de $\chi^2(2)$.

\boxed{Y_k = \dfrac{X_k^2}{\sigma^2} \sim \chi^2(2)}

\vspace{1em}
\subsection*{3. Loi de $\dfrac{T_n}{\sigma^2}$}

On considère :
\[
\frac{T_n}{\sigma^2} = \sum_{k=1}^n \frac{X_k^2}{\sigma^2} = \sum_{k=1}^n Y_k.
\]

Les $Y_k$ sont indépendants et suivent chacun une loi $\chi^2(2)$.

Or, la somme de $n$ variables indépendantes suivant une loi $\chi^2(2)$ suit une loi $\chi^2(2n)$ :
\[
\frac{T_n}{\sigma^2} \sim \chi^2(2n).
\]

On peut aussi le démontrer rigoureusement en calculant la fonction caractéristique de $T_n/\sigma^2$, qui vaut :
\[
\varphi_{T_n/\sigma^2}(t) = \left(1 - 2it\right)^{-n},
\]
car $\varphi_{\chi^2(2)}(t) = (1 - 2it)^{-1}$.

\boxed{\dfrac{T_n}{\sigma^2} \sim \chi^2(2n)}

\vspace{1em}
\subsection*{4. Intervalle de confiance au niveau $1 - \alpha$ pour $\sigma$}

Puisque $\dfrac{T_n}{\sigma^2} \sim \chi^2(2n)$, on peut inverser cette relation pour obtenir un intervalle de confiance pour $\sigma$.

Soient $\chi^2_{2n;\,\alpha/2}$ et $\chi^2_{2n;\,1-\alpha/2}$ les quantiles d’ordre $\alpha/2$ et $1 - \alpha/2$ de la loi $\chi^2(2n)$. On a :
\[
\mathbb{P} \left( \chi^2_{2n;\,\alpha/2} \leq \frac{T_n}{\sigma^2} \leq \chi^2_{2n;\,1-\alpha/2} \right) = 1 - \alpha.
\]

En inversant cette inégalité :
\[
\mathbb{P} \left( \sqrt{ \frac{T_n}{\chi^2_{2n;\,1-\alpha/2}} } \leq \sigma \leq \sqrt{ \frac{T_n}{\chi^2_{2n;\,\alpha/2}} } \right) = 1 - \alpha.
\]

On obtient un intervalle de confiance à $1 - \alpha$ pour $\sigma$ :

\[
\boxed{ \left[ \sqrt{ \frac{T_n}{\chi^2_{2n;\,1 - \alpha/2}} },\; \sqrt{ \frac{T_n}{\chi^2_{2n;\,\alpha/2}} } \right] }
\]

\vspace{1em}
\subsection*{5. Application numérique avec $n = 5$ et $X = \{1, 2, 3, 4, 6\}$}

On commence par calculer :
\[
T_5 = 1^2 + 2^2 + 3^2 + 4^2 + 6^2 = 1 + 4 + 9 + 16 + 36 = 66.
\]

On souhaite un intervalle de confiance à 95\% pour $\sigma$, donc $\alpha = 0.05$.

Le nombre de degrés de liberté est $2n = 10$.

D’après les tables de la loi $\chi^2(10)$ :
\[
\chi^2_{10;\,0.025} \approx 20.48, \qquad \chi^2_{10;\,0.975} \approx 3.25.
\]

On remplace dans la formule de l’intervalle :
\[
\left[ \sqrt{ \frac{66}{20.48} },\; \sqrt{ \frac{66}{3.25} } \right] \approx [1.79,\; 4.51].
\]

\boxed{\sigma \in [1.79,\; 4.51]\quad \text{avec une confiance de 95\%}}


\end{document}
